<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Data | Modelling Altcoin Price Variation with Sentiment Based Predictors</title>
  <meta name="description" content="Chapter 2 Data | Modelling Altcoin Price Variation with Sentiment Based Predictors" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Data | Modelling Altcoin Price Variation with Sentiment Based Predictors" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Data | Modelling Altcoin Price Variation with Sentiment Based Predictors" />
  
  
  

<meta name="author" content="Daniel Spottiswood" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="literature-review.html"/>
<link rel="next" href="3-method.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> thesisdowndss::thesis_pdf: default</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="literature-review.html"><a href="literature-review.html"><i class="fa fa-check"></i>Literature Review</a></li>
<li class="chapter" data-level="2" data-path="2-data.html"><a href="2-data.html"><i class="fa fa-check"></i><b>2</b> Data</a><ul>
<li class="chapter" data-level="2.1" data-path="2-data.html"><a href="2-data.html#twitter"><i class="fa fa-check"></i><b>2.1</b> Twitter</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-data.html"><a href="2-data.html#tweet-removal"><i class="fa fa-check"></i><b>2.1.1</b> Tweet Removal</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-data.html"><a href="2-data.html#sentiment-analysis"><i class="fa fa-check"></i><b>2.1.2</b> Sentiment Analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-data.html"><a href="2-data.html#google-search-volume"><i class="fa fa-check"></i><b>2.2</b> Google Search Volume</a></li>
<li class="chapter" data-level="2.3" data-path="2-data.html"><a href="2-data.html#price-and-volume"><i class="fa fa-check"></i><b>2.3</b> Price and Volume</a></li>
<li class="chapter" data-level="2.4" data-path="2-data.html"><a href="2-data.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>2.4</b> Exploratory Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-method.html"><a href="3-method.html"><i class="fa fa-check"></i><b>3</b> Methodology</a><ul>
<li class="chapter" data-level="3.1" data-path="3-method.html"><a href="3-method.html#log-returns"><i class="fa fa-check"></i><b>3.1</b> Log Returns</a></li>
<li class="chapter" data-level="3.2" data-path="3-method.html"><a href="3-method.html#xgboost"><i class="fa fa-check"></i><b>3.2</b> XGBoost</a></li>
<li class="chapter" data-level="3.3" data-path="3-method.html"><a href="3-method.html#long-short-term-memory"><i class="fa fa-check"></i><b>3.3</b> Long Short-Term Memory</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-method.html"><a href="3-method.html#layers"><i class="fa fa-check"></i><b>3.3.1</b> Layers</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-method.html"><a href="3-method.html#dropout"><i class="fa fa-check"></i><b>3.3.2</b> Dropout</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-results.html"><a href="4-results.html"><i class="fa fa-check"></i><b>4</b> Results</a><ul>
<li class="chapter" data-level="4.1" data-path="4-results.html"><a href="4-results.html#trading-strategies"><i class="fa fa-check"></i><b>4.1</b> Trading Strategies</a></li>
<li class="chapter" data-level="4.2" data-path="4-results.html"><a href="4-results.html#visualization-of-trades"><i class="fa fa-check"></i><b>4.2</b> Visualization of trades</a></li>
<li class="chapter" data-level="4.3" data-path="4-results.html"><a href="4-results.html#the-mean-pnls-across-hours"><i class="fa fa-check"></i><b>4.3</b> The mean pnl’s across hours</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i>Discussion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-the-first-appendix.html"><a href="A-the-first-appendix.html"><i class="fa fa-check"></i><b>A</b> The First Appendix</a></li>
<li class="chapter" data-level="B" data-path="B-the-second-appendix-for-fun.html"><a href="B-the-second-appendix-for-fun.html"><i class="fa fa-check"></i><b>B</b> The Second Appendix, for Fun</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelling Altcoin Price Variation with Sentiment Based Predictors</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Data</h1>
<p>Data was collected in weekly increments from October 20th to March 17th, accumulating in over 3,500 data points.</p>
<div id="twitter" class="section level2">
<h2><span class="header-section-number">2.1</span> Twitter</h2>
<p>Twitter is one of the largest social media platforms, distinct in its focus on short text. It has a large cryptocurrency community with a combination of individual traders and key moguls who dictate the trading flow of thousands.</p>
<p>The Twitter API allows one to pull all tweets containing certain keywords. I collected all tweets in English containing the terms ‘zcash’ or ‘zec’. With over 130 thousand tweets during the specified time period, there are on average 37.5 tweets every hour before accounting for bots or other confounding factors.</p>
<p>To remain consistent with the other features I aggregated the twitter data by the hour. As shown in Figure <a href="2-data.html#fig:dailytweets">2.1</a>, while there is a daily trend in the number of tweets every hour the autocorrelation is not extreme enough to require adjustment. I chose to explore the mean sentiment, a favorite weighted sentiment, and a retweet weighted sentiment as well as the tweet count. Testing showed that the mean sentiment, retweet weighted sentiment, and tweet count, were instrumental to the model, while the favorite weighted sentiment seemed to add noise and caused the model to overfit.</p>
<div class="figure" style="text-align: center"><span id="fig:dailytweets"></span>
<img src="thesis_files/figure-html/dailytweets-1.png" alt="Hourly Tweet Counts" width="672" />
<p class="caption">
Figure 2.1: Hourly Tweet Counts
</p>
</div>
<div id="tweet-removal" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Tweet Removal</h3>
<p>While I previously described the unique name as being one of the deciding factors in choosing Zcash, a hurdle arose as the string ‘zec’ appears both in Zechariah, a hebrew prophet, and is an acronym for the Zimbabwe Electoral Commission. A non negligible portion of the tweets collected, approximately 2-3%, referenced one of these two topics. Therefore, I removed all tweets containing ‘Zechariah’ as well as common terms appearing in relation to the election: ‘election’, ‘Zimbabwe’, ‘Botswana’, etc..</p>
<p>Twitter has taken aggressive measures to remove bots from it’s platform, however, a recent study estimated that 9 to 15% of accounts are bots while another study found that two thirds of shared links are posted by bots<span class="citation">(Wojcik, n.d.,<span class="citation">Varol, Ferrara, Davis, Menczer, &amp; Flammini (2017)</span>)</span>. This may be even higher in the cryptocurrency space due to the potential profits if one can swing public opinion. I use Michael Kearney’s ‘tweetbotornot’ package to eliminate this noise by classifying and removing bots. Michael Kearney’s package applies an extreme gradient boosting model to a user’s tweets and bio to predict whether or not they are a bot with over 93% accuracy. Due to the high number of bots and the large quantity of tweets that they post, I do not expect these accuracy rates to transfer perfectly onto my dataset. I manually tested 30 users that were classified as bots and 30 users classified as non-bots, the results are shown in Table <a href="2-data.html#tab:botexp">2.1</a>. An unknown refers to an account that was removed, which we can speculate would often be bots. This test used a .7 threshold that was selected in the validation phase. My own distinctions are not objective, however, blind testing was performed to eliminate partial bias from these results. The results show statistically significant differences between the groups. Out of the 15 bots, most were classified correctly, however, there was still a significant portion of false positives. While this is concerning, it seems likely that for modeling purposes it is more important to remove the systematic bias of bots than to capture the full extent of authentic signal. This was supported empirically as it was advantageous to remove a larger portion of bots at the expense of removing some authentic accounts.</p>
<table>
<caption><span id="tab:botexp">Table 2.1: </span>Bot Model Accuracy</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">True</th>
<th align="right">False</th>
<th align="right">Unknown</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bot</td>
<td align="right">14</td>
<td align="right">4</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td>Non-Bot</td>
<td align="right">26</td>
<td align="right">1</td>
<td align="right">3</td>
</tr>
</tbody>
</table>
<p>Overall slightly over half of the users and half of the tweets were removed. After removing tweets not related to the cryptocurrency Zcash and those posted by potential bots, the dataset contains approximately 57 thousand tweets for an average of 16 tweets per hour.</p>
</div>
<div id="sentiment-analysis" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Sentiment Analysis</h3>
<p>R has multiple packages that perform sentiment analysis on texts. I implemented two of the most popular libraries The ‘SentimentAnalysis’ package allows the use of many different dictionaries, however, I chose the two most suitable to my goals: Henry’s finance specific dictionary and the QDAP dictionary put together by Tyler Rinker. ‘SentimentR’ similarly utilizes the QDAP dictionary; however, it also takes into account valence shifters such as negators to improve performance over a simple dictionary lookup while still maintaining speed. To assess performance, I randomly sampled 100 tweets and cross-checked their predictions using my own classifications as the ground truth, the results are shown in Table <a href="2-data.html#tab:sentimentexp">2.2</a>. Tweets were classified into three groups: positive, neutral, and negative. ‘Sentimentr’ had the best performance when looking at weighted F1 scores, which given the class imbalance is a better measurement of accuracy.</p>
<span class="math display" id="eq:1">\[\begin{align}
  Weighted \; F1 = \sum_{i=1}^{numclasses}{2*\frac{(precision_{class_i} + recall_{class_i})}{(precision_{class_i}*recall_{class_i})}} \tag{2.1} \\ 
\end{align}\]</span>
<table>
<caption><span id="tab:sentimentexp">Table 2.2: </span>Sentiment Package Accuracy</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Henry’s Financial</th>
<th align="right">QDAP</th>
<th align="right">SentimentR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>F1</td>
<td align="right">0.55</td>
<td align="right">0.62</td>
<td align="right">0.62</td>
</tr>
<tr class="even">
<td>Weighted F1</td>
<td align="right">0.62</td>
<td align="right">0.63</td>
<td align="right">0.70</td>
</tr>
</tbody>
</table>
<p>The confusion matrix using ‘SentimentR’ is in Table <a href="2-data.html#tab:sentimentcheck">2.3</a>. It is important to note that most of the errors occur through neutral samples being labeled as positive or negative and vice-versa. There are relatively few occurrences of negative/positive samples being classified as the opposite. One example of a negative outlook tweet that was labeled as positive is the following: “All privacy coins are held together with duct tape + paperclips, in particular, all XMR and ZEC forks. Epic work by…”. This is a tweet that even the most sophisticated NLP algorithm would struggle with due to the ambiguity of the metaphor and the positive connotation of “epic”.</p>
<table>
<caption><span id="tab:sentimentcheck">Table 2.3: </span>SentimentR Confusion Matrix</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Obs. Negative</th>
<th align="right">Obs. Neutral</th>
<th align="right">Obs. Positive</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Negative</td>
<td align="right">6</td>
<td align="right">8</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td>Neutral</td>
<td align="right">0</td>
<td align="right">26</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td>Positive</td>
<td align="right">3</td>
<td align="right">14</td>
<td align="right">26</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="google-search-volume" class="section level2">
<h2><span class="header-section-number">2.2</span> Google Search Volume</h2>
<p>Google trends displays normalized search volume for a given keyword. I collected trends data for the terms ‘zec’, ‘zcash’, and ‘bitcoin’. I use the ratio of ‘zec’ and ‘zcash’ search volumes to ‘bitcoin’ in order to account for general trends in interest in cryptocurrency. Figure <a href="2-data.html#fig:dailygtrends">2.2</a> illustrates that the hourly ratios does not display autocorrelation that needs correction.</p>
<div class="figure" style="text-align: center"><span id="fig:dailygtrends"></span>
<img src="thesis_files/figure-html/dailygtrends-1.png" alt="Hourly Gtrends ratios" width="672" />
<p class="caption">
Figure 2.2: Hourly Gtrends ratios
</p>
</div>
</div>
<div id="price-and-volume" class="section level2">
<h2><span class="header-section-number">2.3</span> Price and Volume</h2>
<p>Cryptocompare uses a sophisticated aggregation method to accurately assess real prices for cryptocurrencies given the multitude of markets with different liquidity and regulations. They use a volume weighted average with an additional decay based on the time since the most recent trade and outlier detection.</p>
<p>Volume to and volume from correspond to the volume in and out of a certain currency in the pair. I use the conversion rate of ZEC to USD. Interestingly as shown in <a href="#fig:"><strong>??</strong></a>, as price increaseed in January and early February the volume initially increased dramatically, but then tailed off.</p>
<div class="figure" style="text-align: center">
<img src="thesis_files/figure-html/unnamed-chunk-2-1.png" alt=" " width="672" />
<p class="caption">
</p>
</div>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2><span class="header-section-number">2.4</span> Exploratory Data Analysis</h2>
<p>Correlations between the model features and four hour log returns are shown in Figure <a href="2-data.html#fig:correlations">2.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:correlations"></span>
<img src="thesis_files/figure-html/correlations-1.png" alt="Correlations with Log Returns" width="672" />
<p class="caption">
Figure 2.3: Correlations with Log Returns
</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="literature-review.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="3-method.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
